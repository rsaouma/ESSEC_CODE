{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PxJCQ2NHlGpE"
   },
   "source": [
    "# Term Project Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GFVRUEWylGpG"
   },
   "source": [
    "In this mini-project our will goal will be to look at Data published by US Census Bureau about the housing market in California. Given i set of features our goal is to find a model that predicts the median housing price in any district. The case has been taken from the book \"Hands-On Machine Learning with Scikit-learn & TensorFlow\" - Aurelien Geron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0gnUSMYIlGpI"
   },
   "source": [
    "Like all seasoned data scientists we start by loading our notebook with the standard toolbox of packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jEyNj5yJlGpJ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2zeSry3GlGpO"
   },
   "source": [
    "### I - First we frame the problem:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HLMGA6yglGpP"
   },
   "source": [
    "The first task we need to establish is what is the objective of our Machine learning problem. How do we intend to use this data and model in the future. Knowing the objectives is crucial in all the decision we will be taking while building our model. Decisions that relate to anything from how to clean the data to how to evaluate the model.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u7LH5WgUlGpQ"
   },
   "source": [
    "Let's assume we are investors and we are trying to find undervalued districts. In this case we chose the California Housing Prices dataset. This dataset was based on data from the 1990 California census.\n",
    "It is not exactly recent (you could still afford a nice house in the Bay Area at the\n",
    "time), but it has many qualities for learning, so we will pretend it is recent data. \n",
    "Your boss asks you to build a model to predict the median housing price in any district given the metrics in the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-p3Tg0JylGpS"
   },
   "source": [
    "The first questions we need to answers are: What kind of problem are we looking at?\n",
    "\n",
    "In this particular case it is obvious that we are dealing with a supervised learning problem that requieres a multivariate regression analysis. \n",
    "\n",
    "This said we can still reframe the problem differently at this stage by making the target a price range instead of a median price. In this case we will be dealing with a classification problem.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GBvbpD-mlGpT"
   },
   "source": [
    "### II - Get the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ugIFo9AnlGpU"
   },
   "outputs": [],
   "source": [
    "data_table = pd.read_csv('housing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oTJ1glKDlGpX",
    "outputId": "9a8b4af2-d4f5-4637-e461-ffd2ada4bc2d"
   },
   "outputs": [],
   "source": [
    "data_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cW2bL5sWlGpa"
   },
   "source": [
    "The content and structure of our dataset looks fairly comprehansible. We can explore the data even more in depth by applying the the .info() method to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SdIN5-jWlGpb",
    "outputId": "8b03d1b1-fe17-49ed-b431-365d95c1fe67"
   },
   "outputs": [],
   "source": [
    "data_table.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jZ4fr28xlGpf"
   },
   "source": [
    "#### Initial observations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DieoCJeHlGpg"
   },
   "source": [
    "   - The __total_bedrooms__ feature has only 20433 non-values which means we need to deal with those missing vales.\n",
    "   - All features are numerical and stored as type float64 except __ocean_proximity__. Pandas loaded as type 'Object' which be any Python Object but by compering with the the .head() output we know we are dealing with strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AZkw8hMUlGph",
    "outputId": "c92a75a8-587b-4d44-e20f-62febec4a3c0"
   },
   "outputs": [],
   "source": [
    "data_table['ocean_proximity'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i6r4EQmslGpi"
   },
   "source": [
    "Next, lets look at the summary of the other features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b8Arzv0clGpj",
    "outputId": "7b16cf67-7d3f-41e7-b96f-acdd586a59a7"
   },
   "outputs": [],
   "source": [
    "data_table.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "83uIBHxdlGpl"
   },
   "outputs": [],
   "source": [
    "\n",
    "data_table.hist(bins=50, figsize=(20,15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0zTVA4BWlGpn"
   },
   "source": [
    "### To Notice:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H0S5a0milGpo"
   },
   "source": [
    "- The median income feature does not seem to be expressed in US terms. After checking I realized that the data has been scaled and capped at 15 and the lower side is 0.5. \n",
    "- THe housing median age and median house value are also capped. The latter could be a problem since it is our target attribute. This is not ideal, and we need to see how we can fix it. We can't predict properly when the data is capped to 500,000, which means we will wrongly predict houses with value higher than 500k.\n",
    "- The features in general vary a lot in scale.\n",
    "- Many features exhibit distribuations that are far from being normal. In fact several have skews. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YHn5kqzTlGpo"
   },
   "source": [
    "### Visualising geographical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6OYqD-CNlGpp",
    "outputId": "60f32e80-93c2-48b9-b4f4-5cc0a72e7d8b"
   },
   "outputs": [],
   "source": [
    "data_table.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hZTGTvzglGpr",
    "outputId": "444a6bb3-56d4-4338-dc7b-5155be44d9b8"
   },
   "outputs": [],
   "source": [
    "data_table.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ryJxmhZelGps"
   },
   "source": [
    "By adding the alpha argument we see a much more nuanced visualision of California, with two concertrated areas around Los Angelos and Central Valley."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ky8EmxgIlGpt"
   },
   "source": [
    "Now lets add housing prices to the picture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9BNDYsVWlGpt",
    "outputId": "ad792e0c-0978-4033-ce47-1ae2761bb54f"
   },
   "outputs": [],
   "source": [
    "data_table.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.4,\n",
    "    s=data_table[\"population\"]/100, label=\"population\", figsize=(10,7),\n",
    "    c=\"median_house_value\", cmap=plt.get_cmap(\"jet\"), colorbar=True,\n",
    "    sharex=False)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-RmVmFB-lGpv"
   },
   "source": [
    "### Exploring correlations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RysTJsx4lGpv"
   },
   "outputs": [],
   "source": [
    "corr_matrix = data_table.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zz6J-GJblGpw",
    "outputId": "0731abe8-0f19-435b-9608-381925f25db3"
   },
   "outputs": [],
   "source": [
    "corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dcXK_LB3lGpy"
   },
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v0fZCJfKlGpz",
    "outputId": "de431695-4fdf-44de-8f47-ba43df387a24"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "attributes = [\"median_house_value\", \"median_income\", \"total_rooms\",\n",
    "              \"housing_median_age\"]\n",
    "scatter_matrix(data_table[attributes], figsize=(12, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8qksreJ1lGp0",
    "outputId": "9e56dccb-154d-4772-821e-4bd371e9a9c5"
   },
   "outputs": [],
   "source": [
    "data_table.plot(kind=\"scatter\", x=\"median_income\", y=\"median_house_value\",\n",
    "             alpha=0.1)\n",
    "plt.axis([0, 16, 0, 550000])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UZsTohkQlGp2"
   },
   "source": [
    "One last thig you might want to think of while preparing your data is to try to combine some features together. For example the total number of rooms in a district is not very usefull if you don't know how many households there are. What you really want is the number of room per household. You also might want to look at bedrooms relative to the number of total rooms. We hence create a couple of new features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DAyToS6glGp2"
   },
   "outputs": [],
   "source": [
    "data_table[\"rooms_per_household\"] = data_table[\"total_rooms\"]/data_table[\"households\"]\n",
    "data_table[\"bedrooms_per_room\"] = data_table[\"total_bedrooms\"]/data_table[\"total_rooms\"]\n",
    "data_table[\"population_per_household\"]=data_table[\"population\"]/data_table[\"households\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5l8wuARdlGp3",
    "outputId": "ba0a1a86-c79e-410c-bbfb-74cafa558f23"
   },
   "outputs": [],
   "source": [
    "corr_matrix = data_table.corr()\n",
    "corr_matrix[\"median_house_value\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v_WuXwyWlGp5"
   },
   "source": [
    "This is type of analysis is not exhaustive. It is just an illustrative example on how to think about your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6IEz8KoGlGp5"
   },
   "source": [
    "### Prepare the Data for Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gpcVqUC9lGp5"
   },
   "source": [
    "Let's start by cleaning the data. We have seen earlier that total_bedrooms feature has soem missing value. We have three options to deal with that:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gDECKQrvlGp6"
   },
   "source": [
    "### Missing Data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GD8FI9P8lGp6"
   },
   "source": [
    "- Get rid of the corresponding districts\n",
    "- Get rid of the whole feature\n",
    "- Set the values to some value(mean, median, zero..etc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xbVwvmJclGp6"
   },
   "source": [
    "For each option pandas offers a function: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uc_aQBjylGp6",
    "outputId": "c409100f-3318-4ba6-a085-971edfd58ba4"
   },
   "outputs": [],
   "source": [
    "sample_incomplete_rows = data_table[data_table.isnull().any(axis=1)].head()\n",
    "sample_incomplete_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gjNBur3plGp8",
    "outputId": "a830d010-7178-434b-da77-07da2ee7e1e5"
   },
   "outputs": [],
   "source": [
    "sample_incomplete_rows.dropna(subset=[\"total_bedrooms\"])    # option 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r75sjyLhlGp9",
    "outputId": "7d6e832e-989b-4d61-ae9f-734051a8bc56"
   },
   "outputs": [],
   "source": [
    "sample_incomplete_rows.drop(\"total_bedrooms\", axis=1)       # option 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XHTUkVSglGp-"
   },
   "outputs": [],
   "source": [
    "median = data_table[\"total_bedrooms\"].median()\n",
    "sample_incomplete_rows[\"total_bedrooms\"].fillna(median, inplace=True) # option 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-ik8uL91lGp_"
   },
   "outputs": [],
   "source": [
    "data_table[\"total_bedrooms\"].fillna(median, inplace=True)\n",
    "data_table[\"bedrooms_per_room\"].fillna(median, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y-xt1ANVlGqA",
    "outputId": "6a8c4e1f-4870-490a-beab-81746186069a"
   },
   "outputs": [],
   "source": [
    "data_table.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dAJYLtkKlGqB"
   },
   "source": [
    "We opt for the third method. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pjMusgwRlGqB"
   },
   "source": [
    "### Categorical Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NYdRXjCBlGqC"
   },
   "outputs": [],
   "source": [
    "housing_cat = data_table[[\"ocean_proximity\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lu24d7oElGqD",
    "outputId": "7f54d34e-c2af-497f-830f-dbe093c8f7a7"
   },
   "outputs": [],
   "source": [
    "housing_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lgyp3hRtlGqE"
   },
   "source": [
    "Most Machine learning algorithims work only with number. Hence we need to transform those categories to numbers:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o-90v6LTlGqE"
   },
   "source": [
    "We this we will use the SKlearn calss called OrdinalEncoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7jp7q89mlGqE"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "housing_cat_encoded = ordinal_encoder.fit_transform(housing_cat)\n",
    "housing_cat_encoded = pd.DataFrame(housing_cat_encoded)\n",
    "housing_cat_encoded.columns = ['Category']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OZHFjqzllGqF"
   },
   "source": [
    "What is the problem with this encoding?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2C7lt-uclGqG",
    "outputId": "a2ed5aee-5064-4170-d95b-943bb6590d90"
   },
   "outputs": [],
   "source": [
    "housing_cat_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9-EDwHq6lGqG"
   },
   "source": [
    "One issue with this encoding as we have discussed in previous class was the fact that some ML algorithims might assume that two nearby values are more similar that two distant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LlpMpI7clGqH",
    "outputId": "ec3bdef3-5c03-4dda-b26d-55695e866640"
   },
   "outputs": [],
   "source": [
    "data_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tIcLGs3vlGqI",
    "outputId": "b94caeba-e6ed-4e61-cf8d-30d49a9b5788"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "cat_encoder = OneHotEncoder()\n",
    "housing_cat_1hot = cat_encoder.fit_transform(housing_cat)\n",
    "housing_cat_1hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NeyD4d6HlGqJ",
    "outputId": "fb1d1a7f-dafe-425b-c1f0-c40e288a93b5"
   },
   "outputs": [],
   "source": [
    "columns =cat_encoder.categories_[0].tolist()\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y_AuSsRnlGqJ"
   },
   "outputs": [],
   "source": [
    "data  = housing_cat_1hot.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lu5PE4l1lGqK"
   },
   "outputs": [],
   "source": [
    "n_frame = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u-feRnQtlGqL"
   },
   "outputs": [],
   "source": [
    "n_frame.columns=columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xsEXuy_flGqM",
    "outputId": "292f6ff6-c52b-4caf-d896-2880003333f3"
   },
   "outputs": [],
   "source": [
    "n_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f55-yTJllGqN"
   },
   "outputs": [],
   "source": [
    "n_data_table = pd.concat([data_table,n_frame],axis=1,sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eC1VhnQAlGqO",
    "outputId": "a2c8d0ee-4b40-4899-9338-7fd6c35503cb"
   },
   "outputs": [],
   "source": [
    "n_data_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jCI_kHnQlGqP"
   },
   "outputs": [],
   "source": [
    "n_data_table = n_data_table.drop('ocean_proximity',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7IBNLYUPlGqQ",
    "outputId": "4758da46-1944-4ff6-d8c8-5047c4c7fd71"
   },
   "outputs": [],
   "source": [
    "n_data_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dNvaEmPilGqR",
    "outputId": "8d3fffa2-848a-47a7-e3f4-74045449449d"
   },
   "outputs": [],
   "source": [
    "n_data_table.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ffpndSuklGqS"
   },
   "source": [
    "### Split the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ukqAulHXlGqS"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "\n",
    "y = n_data_table['median_house_value']\n",
    "X = n_data_table.drop('median_house_value',axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=3)\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jodg3EUdlGqT"
   },
   "source": [
    "### Apply Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3zgbYJswlGqT"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import  Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "linreg = LinearRegression().fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yO9vlDVrormV"
   },
   "source": [
    "We first look at the outcome of an OLS linear regression:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PdnjzeSrlGqU",
    "outputId": "5f476942-ccec-4bb9-b9a5-cd57f4c82aeb"
   },
   "outputs": [],
   "source": [
    "print('linear model coeff (w): {}'\n",
    "     .format(linreg.coef_))\n",
    "print('linear model intercept (b): {:.3f}'\n",
    "     .format(linreg.intercept_))\n",
    "print('R-squared score (training): {:.3f}'\n",
    "     .format(linreg.score(X_train_scaled, y_train)))\n",
    "print('R-squared score (test): {:.3f}'\n",
    "     .format(linreg.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rBsaya0wpP19"
   },
   "source": [
    "The results don't look great for linear regression - Oddly the test score is higher than the training score which is usually a sign of underfitting.\n",
    "Next we try to run a lasso regression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9du_D77HlGqV",
    "outputId": "88b3dc45-2ac0-49c8-cd95-8604666fb2bd"
   },
   "outputs": [],
   "source": [
    "linlasso = Lasso(alpha=20.0, max_iter = 10000).fit(X_train_scaled, y_train)\n",
    "\n",
    "print('Crime dataset')\n",
    "print('lasso regression linear model intercept: {}'\n",
    "     .format(linlasso.intercept_))\n",
    "print('lasso regression linear model coeff:\\n{}'\n",
    "     .format(linlasso.coef_))\n",
    "print('Non-zero features: {}'\n",
    "     .format(np.sum(linlasso.coef_ != 0)))\n",
    "print('R-squared score (training): {:.3f}'\n",
    "     .format(linlasso.score(X_train_scaled, y_train)))\n",
    "print('R-squared score (test): {:.3f}\\n'\n",
    "     .format(linlasso.score(X_test_scaled, y_test)))\n",
    "print('Features with non-zero weight (sorted by absolute magnitude):')\n",
    "\n",
    "for e in sorted (list(zip(list(X_train), linlasso.coef_)),\n",
    "                key = lambda e: -abs(e[1])):\n",
    "    if e[1] != 0:\n",
    "        print('\\t{}, {:.3f}'.format(e[0], e[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "akwFj1E5lGqV",
    "outputId": "e652449e-136a-46e0-ff15-c57b448d81bb"
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "\n",
    "cv_scores = cross_val_score(linlasso, X, y,cv=5)\n",
    "\n",
    "print('Cross-validation scores (3-fold):', cv_scores)\n",
    "print('Mean cross-validation score (3-fold): {:.3f}'\n",
    "     .format(np.mean(cv_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g8i8WzajlGqW",
    "outputId": "5fecf64d-2781-4c15-a53b-b33aab2d87fc"
   },
   "outputs": [],
   "source": [
    "print('Lasso regression: effect of alpha regularization\\n\\\n",
    "parameter on number of features kept in final model\\n')\n",
    "\n",
    "for alpha in [0.5, 1, 2, 3, 5, 10, 20, 50]:\n",
    "    linlasso = Lasso(alpha, max_iter = 10000).fit(X_train_scaled, y_train)\n",
    "    r2_train = linlasso.score(X_train_scaled, y_train)\n",
    "    r2_test = linlasso.score(X_test_scaled, y_test)\n",
    "    \n",
    "    print('Alpha = {:.2f}\\nFeatures kept: {}, r-squared training: {:.2f}, \\\n",
    "r-squared test: {:.2f}\\n'\n",
    "         .format(alpha, np.sum(linlasso.coef_ != 0), r2_train, r2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jpacaWXrlGqX",
    "outputId": "4cc268b8-a62d-413d-c60f-ca9104a6af6d"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "param_range = np.linspace(0, 50, 10)\n",
    "train_scores, test_scores = validation_curve(Lasso( max_iter = 10000), X, y,\n",
    "                                            param_name='alpha',\n",
    "                                            param_range=param_range, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "04aEsKN5lGqY",
    "outputId": "dbaf991f-9963-4060-bc90-43aefd1a7e22"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "tree_reg = DecisionTreeRegressor(random_state=42)\n",
    "tree_reg.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dl4I1hHFlGqZ",
    "outputId": "e46e7128-7658-4b9f-bae4-65514986542c"
   },
   "outputs": [],
   "source": [
    "housing_predictions = tree_reg.predict(X_train_scaled)\n",
    "tree_mse = mean_squared_error(y_train, housing_predictions)\n",
    "tree_rmse = np.sqrt(tree_mse)\n",
    "tree_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q_nrKIVmlGqa",
    "outputId": "677e3a1e-9d4a-497f-aacd-72e97ae5b4b4"
   },
   "outputs": [],
   "source": [
    "housing_predictions = tree_reg.predict(X_test_scaled)\n",
    "tree_mse = mean_squared_error(y_test, housing_predictions)\n",
    "tree_rmse = np.sqrt(tree_mse)\n",
    "tree_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8hc4MU_plGqb",
    "outputId": "8373a0bf-5ad0-4232-ef45-db08993de826"
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gxxaD4dmlGqc"
   },
   "outputs": [],
   "source": [
    "y_classes = y.copy()\n",
    "y_classes[y_classes <= 100000] = 1\n",
    "y_classes[y_classes <= 200000] = 2\n",
    "y_classes[y_classes <= 300000] = 3\n",
    "y_classes[y_classes <= 400000] = 4\n",
    "y_classes[y_classes <= 500000] = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8CgH1cIclGqc",
    "outputId": "3af6a563-51d6-44da-b021-c1e70122358a"
   },
   "outputs": [],
   "source": [
    "y_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8R2MjwqflGqd"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Project_Example.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
